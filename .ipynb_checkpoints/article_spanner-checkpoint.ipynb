{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9aca300-0526-4078-a17e-32ba5643e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "import string\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0064227-1245-4ffb-b7ce-e5cd5dd4ea91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 reviews found.\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(open(os.path.join('data', 'positive.review')))\n",
    "review_texts = soup.findAll('review_text')\n",
    "review_texts_contents = [review_text.text for review_text in review_texts]\n",
    "del review_texts\n",
    "print(len(review_texts_contents), \"reviews found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "860f4880-9b83-4401-ac82-dc8d2367eb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7386 unique tokens found\n"
     ]
    }
   ],
   "source": [
    "def tokenize(s) :\n",
    "    s = s.lower()\n",
    "    s = nltk.tokenize.word_tokenize(s)\n",
    "    s = [token.translate(str.maketrans('', '', string.punctuation)) for token in s if token.isalpha()]\n",
    "    return s\n",
    "\n",
    "tokenizer = Tokenizer(oov_token='<OOV>', analyzer=tokenize)\n",
    "tokenizer.fit_on_texts(review_texts_contents)\n",
    "sequences = tokenizer.texts_to_sequences(review_texts_contents)\n",
    "print(len(tokenizer.word_index), 'unique tokens found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734e02ac-a250-4db8-9db9-fbb9430c1cfb",
   "metadata": {},
   "source": [
    "## Frequency Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d1d82eee-5ddc-475f-9f8e-25bb51cfab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create defaultdicts for p_w0, p_wt, and p_wT\n",
    "p_w0 = defaultdict(int)\n",
    "p_wt = defaultdict(int)\n",
    "p_wT = defaultdict(int)\n",
    "\n",
    "for sequence in sequences:\n",
    "    if len(sequence) > 1:\n",
    "        first_word, second_word = sequence[:2]\n",
    "        p_w0[(first_word, second_word)] += 1\n",
    "        last_word, second_last_word = sequence[-1], sequence[-2]\n",
    "        p_wT[(second_last_word, last_word)] += 1\n",
    "    \n",
    "    for t in range(1, len(sequence) - 1):\n",
    "        w_prev, w, w_next = sequence[t - 1], sequence[t], sequence[t + 1]\n",
    "        p_wt[(w_prev, w, w_next)] += 1\n",
    "\n",
    "# Convert defaultdicts to pandas Series\n",
    "p_w0 = pd.Series(p_w0)\n",
    "p_wt = pd.Series(p_wt)\n",
    "p_wT = pd.Series(p_wT)\n",
    "p_w0.index.names = ([\"Word@(0)\", \"Word@(1)\"])\n",
    "p_wt.index.names = ([\"Word@(t-1)\", \"Word@(t)\" ,\"Word@(t+1)\"])\n",
    "p_wT.index.names = ([\"Word@(T-1)\", \"Word@(T)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfd9396-9b2a-45e9-ac56-e3ee11733011",
   "metadata": {},
   "source": [
    "## Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a21dea2c-f9f8-43ab-b985-164cb0e97b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word@(0)\n",
       "2       1.0\n",
       "3       1.0\n",
       "5       1.0\n",
       "6       1.0\n",
       "7       1.0\n",
       "       ... \n",
       "5322    1.0\n",
       "5446    1.0\n",
       "6203    1.0\n",
       "6761    1.0\n",
       "7314    1.0\n",
       "Length: 164, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Word@(t-1)  Word@(t+1)\n",
       "2           2             1.0\n",
       "            3             1.0\n",
       "            4             1.0\n",
       "            5             1.0\n",
       "            6             1.0\n",
       "                         ... \n",
       "7381        2             1.0\n",
       "7382        13            1.0\n",
       "7383        16            1.0\n",
       "7384        7             1.0\n",
       "7385        6             1.0\n",
       "Length: 61451, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Word@(T)\n",
       "2       1.0\n",
       "3       1.0\n",
       "5       1.0\n",
       "6       1.0\n",
       "7       1.0\n",
       "       ... \n",
       "7216    1.0\n",
       "7230    1.0\n",
       "7300    1.0\n",
       "7305    1.0\n",
       "7386    1.0\n",
       "Length: 558, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "M = len(tokenizer.word_index.values())\n",
    "p_w0 = p_w0.sort_index()\n",
    "p_wt = p_wt.sort_index()\n",
    "p_wT = p_wT.sort_index()\n",
    "\n",
    "p_w0 = (p_w0)/ (p_w0.groupby(level=\"Word@(0)\").sum())\n",
    "p_wT = (p_wT)/ (p_wT.groupby(level=\"Word@(T)\").sum())\n",
    "p_wt = (p_wt) / (p_wt.groupby(level=[\"Word@(t-1)\", \"Word@(t+1)\"]).sum())\n",
    "\n",
    "display(p_w0.groupby(level=0).sum(), p_wt.groupby(level=[\"Word@(t-1)\", \"Word@(t+1)\"]).sum(), p_wT.groupby(level=1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4616e59a-87dd-4b40-8243-f1bf14cba80a",
   "metadata": {},
   "source": [
    "## Taking log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "de26756e-2406-4b86-9b43-4edbc8dcd929",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p_w0 = np.log(p_w0)\n",
    "log_p_wT = np.log(p_wT)\n",
    "log_p_wt = np.log(p_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "4b6b17fd-deb6-4d80-a83a-3ab76ed68276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word@(t-1)  Word@(t+1)  Word@(t)\n",
       "2           2           4           0.016\n",
       "                        8           0.008\n",
       "                        9           0.008\n",
       "                        10          0.008\n",
       "                        14          0.016\n",
       "                                    ...  \n",
       "7381        2           5           1.000\n",
       "7382        13          532         1.000\n",
       "7383        16          634         1.000\n",
       "7384        7           86          1.000\n",
       "7385        6           15          1.000\n",
       "Length: 87610, dtype: float64"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "88a5e4e9-bdff-4547-afb3-57150b06a873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this item does exactly what it suppose to do it also makes the signal stronger therefore you get better reception worth the money only drawback would be there is a lot of cord hanging around\n",
      "Replaced does with does\n",
      "Replaced it with it\n",
      "Replaced to with to\n",
      "Replaced also with really\n",
      "Replaced signal with signal\n",
      "Replaced get with have\n",
      "Replaced better with am\n",
      "Replaced only with only\n",
      "Replaced drawback with they\n",
      "Replaced is with are\n",
      "Replaced cord with cables\n",
      "Replaced hanging with hanging\n",
      "this item does exactly what it suppose to do it really makes the signal stronger therefore you have am reception worth the money only they would be there are a lot of cables hanging around\n"
     ]
    }
   ],
   "source": [
    "def sample_word(series) :\n",
    "    if series is None :\n",
    "        return 1\n",
    "    return np.random.choice(a = series.index, p=series.values)\n",
    "\n",
    "def translate_2_text(sequence) :\n",
    "    return tokenizer.sequences_to_texts(sequence)\n",
    "\n",
    "def span_text(s, max_replacements = 1):\n",
    "    sequence = tokenizer.texts_to_sequences([s])[0]\n",
    "    sequence_spanned = sequence.copy()\n",
    "    n = len(sequence) // max_replacements\n",
    "    for i in range(0, len(sequence), n) :\n",
    "        random_idx = np.random.choice(range(i, np.min((i + n, len(sequence)))))\n",
    "        if random_idx == 0 :\n",
    "            random_idx += 1\n",
    "        elif random_idx == len(sequence) - 1 :\n",
    "            random_idx -= 1\n",
    "        ser = p_wt.loc[sequence[random_idx - 1], sequence[random_idx + 1]]\n",
    "        if len(ser) > 1 :\n",
    "            tmp = ser[sequence_spanned[random_idx]]\n",
    "            tmp = tmp / (len(ser) - 1)\n",
    "            ser += tmp\n",
    "            ser[sequence_spanned[random_idx]] = 0\n",
    "            \n",
    "        sampled = sample_word(ser)\n",
    "        print(f'Replaced {tokenizer.index_word[sequence_spanned[random_idx]]} with {tokenizer.index_word[sampled]}')\n",
    "        sequence_spanned[random_idx] = sampled\n",
    "        \n",
    "        \n",
    "    return translate_2_text([sequence_spanned])\n",
    "\n",
    "test = sequences[np.random.choice(len(sequences))]\n",
    "print(translate_2_text([test])[0])\n",
    "print(span_text(translate_2_text([test])[0], 10)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3045873f-fa77-4193-a24d-9501c1ab0991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
