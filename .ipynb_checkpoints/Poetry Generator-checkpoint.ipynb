{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97dd3051-d9ef-4c94-8bac-cacd3786d290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac993567-60a3-49cd-b8a4-cf7184752e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0c4d670-38ac-4482-b8b6-5552b2fd5852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[96, 563, 564, 9, 6, 565, 566],\n",
       " [4, 567, 5, 71, 27, 879, 150],\n",
       " [4, 24, 22, 880, 177, 5, 251],\n",
       " [4, 197, 61, 22, 17, 139, 17, 5, 71],\n",
       " [3, 43, 8, 881, 9, 2, 882]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join('data', 'robert_frost.txt')) as f:\n",
    "    sentences = []\n",
    "    for line in f:\n",
    "        line = line.rstrip().lower()\n",
    "        if line:\n",
    "            line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "            sentences.append(line)\n",
    "\n",
    "MAX_VOCAB_SIZE = 3000\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e5afdbf-ff81-41da-b23a-0dba028aad21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[394]\n",
      "[1373]\n",
      "[40]\n",
      "[132]\n",
      "[115]\n",
      "[8]\n",
      "[1981]\n"
     ]
    }
   ],
   "source": [
    "for indx ,i in enumerate(sequences) :\n",
    "    if len(i) < 2 :\n",
    "        print(i)\n",
    "        sequences.pop(indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dc16130-a0af-4c1f-8e64-3b0c55b36d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2198"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = len(tokenizer.word_index)\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa7c5cd2-77f1-43b0-88c8-b0485220e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = pd.Series(dtype = np.float32)\n",
    "index_A1 = pd.MultiIndex.from_tuples([], names=[\"Word@(t-1)\", \"Word@(t)\"])\n",
    "A1 = pd.Series(index = index_A1, dtype = np.float32)\n",
    "index_A2 = pd.MultiIndex.from_tuples([], names=[\"Word@(t-2)\", \"Word@(t-1)\", \"Word@(t)\"])\n",
    "A2 = pd.Series(index = index_A2, dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62f13414-9e70-4639-90b1-6caa3675d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sequence in sequences :\n",
    "    pi.loc[sequence[0]] = pi.get(sequence[0], 0) + 1\n",
    "    A1.loc[(sequence[0], sequence[1])] = A1.get((sequence[0], sequence[1]), 0) + 1\n",
    "    \n",
    "    for i in range(2, len(sequence) - 1) :\n",
    "        A2.loc[(sequence[i-2], sequence[i-1], sequence[i])] = A2.get((sequence[i-2], sequence[i-1], sequence[i]), 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "110c366f-2e66-4993-9723-d399de1125b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96      0.005598\n",
       "4       0.090273\n",
       "3       0.034990\n",
       "66      0.008397\n",
       "341     0.000700\n",
       "          ...   \n",
       "247     0.000700\n",
       "193     0.000700\n",
       "57      0.000700\n",
       "2191    0.000700\n",
       "77      0.000700\n",
       "Length: 300, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = pi / pi.sum()\n",
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a9b3e30-ddc2-4671-a9df-dbafa625889a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word@(t-1)  Word@(t)\n",
       "2           70          0.012195\n",
       "            73          0.024390\n",
       "            79          0.012195\n",
       "            82          0.012195\n",
       "            90          0.012195\n",
       "                          ...   \n",
       "2111        59          1.000000\n",
       "2120        4           1.000000\n",
       "2129        5           1.000000\n",
       "2145        35          1.000000\n",
       "2191        19          1.000000\n",
       "Length: 1195, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1 = A1.sort_index()\n",
    "grouped_sum = A1.groupby(level=0).sum()\n",
    "A1 = A1 / grouped_sum\n",
    "A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ac8dad-3fb4-4dc6-b8a3-38b0a097e019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word@(t-2)  Word@(t-1)  Word@(t)\n",
       "2           22          10          0.250000\n",
       "                        23          0.250000\n",
       "                        436         0.250000\n",
       "                        1594        0.250000\n",
       "            70          105         0.166667\n",
       "                                      ...   \n",
       "2183        4           200         1.000000\n",
       "2190        261         68          1.000000\n",
       "2191        19          2192        1.000000\n",
       "2194        62          259         1.000000\n",
       "2196        441         6           1.000000\n",
       "Length: 6201, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2 = A2.sort_index()\n",
    "grouped_sum_A2 = A2.groupby(level=[0, 1]).sum()\n",
    "A2 = A2 /grouped_sum_A2\n",
    "A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f55c636-1073-4200-8682-c6e30baa7e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_word(series) :\n",
    "    if series is None :\n",
    "        return 1\n",
    "    return np.random.choice(a = series.index, p=series.values)\n",
    "\n",
    "def translate(index_mapping_lst) :\n",
    "    return tokenizer.sequences_to_texts(index_mapping_lst)\n",
    "\n",
    "def generate():\n",
    "    for i in range(4): # generate 4 lines\n",
    "        sentence = []\n",
    "\n",
    "        # initial word\n",
    "        w0 = sample_word(pi)\n",
    "        sentence.append(w0)\n",
    "\n",
    "        #first word\n",
    "        w1 = sample_word(A1.loc[w0])\n",
    "        sentence.append(w1)\n",
    "        \n",
    "        while True:\n",
    "            w2 = sample_word(A2.get((w0, w1), None))\n",
    "            w0 = w1\n",
    "            w1 = w2\n",
    "            if w2 == 1 or len(sentence) > 20:\n",
    "                break\n",
    "            sentence.append(w2)\n",
    "            \n",
    "        print(translate([sentence]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4979a60b-3d82-4d89-b8c2-6e61c25f2e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when i heard them toffile didnt seem to hear the']\n",
      "['at least ive brought you to the door they halted helpless on the new']\n",
      "['first theres the childrens house of']\n",
      "['ill talk to her what does she look like you stay the way hes felt but all the rain and snow']\n"
     ]
    }
   ],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4327996f-b795-4a68-99f3-6295376363a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
